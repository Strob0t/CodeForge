# -- Docs MCP Server ------------------------------
# API endpoint for embeddings (LM Studio, Ollama, OpenAI, etc.)
DOCS_MCP_API_BASE=http://host.docker.internal:1234/v1
DOCS_MCP_API_KEY=lmstudio
DOCS_MCP_EMBEDDING_MODEL=text-embedding-qwen3-embedding-8b

# -- CodeForge Core -----------------------------
# Port for the Go Core HTTP server (default: 8080)
# CODEFORGE_PORT=8080

# -- PostgreSQL ----------------------------------
# Password for PostgreSQL (shared by CodeForge + LiteLLM)
POSTGRES_PASSWORD=codeforge_dev

# -- NATS JetStream --------------------------------
# URL for the NATS message queue
NATS_URL=nats://localhost:4222

# -- LiteLLM Proxy ---------------------------------
# Master key for LiteLLM Proxy authentication
LITELLM_MASTER_KEY=sk-codeforge-dev

# -- LLM Provider API Keys (optional) ------------
# Configure the providers you want to use via LiteLLM
OPENAI_API_KEY=
ANTHROPIC_API_KEY=
GEMINI_API_KEY=
OPENROUTER_API_KEY=

# -- Local Models ---------------------------------
# Ollama endpoint (auto-discovered via /v1/models)
OLLAMA_BASE_URL=http://host.docker.internal:11434
