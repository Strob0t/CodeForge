# ── Docs MCP Server ──────────────────────────────
# API endpoint for embeddings (LM Studio, Ollama, OpenAI, etc.)
DOCS_MCP_API_BASE=http://host.docker.internal:1234/v1
DOCS_MCP_API_KEY=lmstudio
DOCS_MCP_EMBEDDING_MODEL=text-embedding-qwen3-embedding-8b

# ── LiteLLM Proxy (planned) ─────────────────────
# Master key for LiteLLM Proxy authentication
LITELLM_MASTER_KEY=

# ── LLM Provider API Keys (optional) ────────────
# Configure the providers you want to use via LiteLLM
OPENAI_API_KEY=
ANTHROPIC_API_KEY=
GEMINI_API_KEY=
OPENROUTER_API_KEY=

# ── Local Models ─────────────────────────────────
# Ollama endpoint (auto-discovered via /v1/models)
OLLAMA_BASE_URL=http://host.docker.internal:11434
